{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "version 1 - smart classifier pretrained & custom classes\n",
    "date - March 30, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports - done\n",
    "# ------------------------\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import h5py\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "###\n",
    "###\n",
    "%matplotlib inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "\n",
    "\n",
    "# printing platform info\n",
    "# ----------------------\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_multi(a,b):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. a,b are of shape (m,no_latent)\n",
    "    2. output is of shape (m,1)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. direct steps\n",
    "    # ---------------\n",
    "    dot_prod = np.sum(a*b, axis = 1)\n",
    "    norm_a = np.sqrt(np.sum(np.square(a),axis = 1))\n",
    "    norm_b = np.sqrt(np.sum(np.square(b),axis = 1))\n",
    "    out = dot_prod/(norm_a*norm_b)\n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # -------------\n",
    "    return out.reshape(out.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function\n",
    "# ----------------\n",
    "def pre_process_pretrained_model_data(x_in):\n",
    "    \n",
    "    \n",
    "    # inits\n",
    "    # -----\n",
    "    assert torch.mean(x_in) > 1,'Error: data must be in [0,255] range.'\n",
    "    x = copy.deepcopy(x_in)\n",
    "    \n",
    "    # we are using a pretrained model that needs to in [-1,1] range\n",
    "    # -------------------------------------------------------------\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "    std_dev = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)\n",
    "\n",
    "    # make data 3 channel\n",
    "    # bring data to [0,1] first then apply normalise\n",
    "    # ----------------------------------------------\n",
    "    if x.size()[1] == 1:\n",
    "        x = torch.cat((x,x,x), 1)\n",
    "    elif x.size()[1] == 3:\n",
    "        pass\n",
    "    else:\n",
    "        assert 1==2,'Error: number of channels in the input datamust be either 1 or 3.'\n",
    "\n",
    "    # final ops\n",
    "    # ---------\n",
    "    x = x/torch.max(x)\n",
    "    x = (x - mean)/std_dev\n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC - change an torch image to numpy image\n",
    "# ----------------------------------------------\n",
    "def to_numpy_image(xin):\n",
    "    \n",
    "    try:\n",
    "        xin = xin.data.numpy()\n",
    "    except:\n",
    "        xin = xin.numpy()\n",
    "    \n",
    "    xout = np.swapaxes(xin,1,2)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped numpy images\n",
    "    # ---------------------------------\n",
    "    return xout       \n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - converts numpy images to torch tensors for training\n",
    "# -------------------------------------------------------------\n",
    "def setup_image_tensor(xin):\n",
    "    xout = np.swapaxes(xin,1,3)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped torch tensor\n",
    "    # ---------------------------------\n",
    "    xout = torch.from_numpy(xout)\n",
    "    return xout.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load a saved model\n",
    "# --------------------------------\n",
    "\n",
    "def load_saved_model_function(path, use_cuda):\n",
    "    \n",
    "    \n",
    "    ''' path = /folder1/folder2/model_ae.tar format'''\n",
    "    \n",
    "    # 1. loading full model\n",
    "    # ---------------------\n",
    "    model = torch.load(path.replace('.tar','_MODEL.tar'))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "    \n",
    "    # 2. Applying state dict\n",
    "    # ----------------------\n",
    "    if use_cuda == True:\n",
    "        \n",
    "        # loads to GPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "    else:\n",
    "        # loads to CPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        \n",
    "    # loading checkpoint\n",
    "    # -------------------\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # loading optimizer\n",
    "    # -----------------\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if use_cuda == True:\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # loading other stuff\n",
    "    # -------------------\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    loss_mode = checkpoint['loss_mode']\n",
    "    \n",
    "    return model, optimizer, epoch, loss, loss_mode\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to read a single image\n",
    "# --------------------------------------\n",
    "\n",
    "def create_dataset_from_folder_all(infolder,resize,gray_mode,n_h,n_w):\n",
    "    \n",
    "    # 0. global initialisations\n",
    "    # -------------------------\n",
    "    global index_list\n",
    "    index_list = []\n",
    "    \n",
    "    global resize_flag\n",
    "    resize_flag = resize\n",
    "    \n",
    "    global gb_in_folder\n",
    "    gb_in_folder = infolder\n",
    "\n",
    "    global counter\n",
    "    counter = 0\n",
    "    \n",
    "    global new_h\n",
    "    new_h = n_h\n",
    "    \n",
    "    global new_w\n",
    "    new_w = n_w\n",
    "    \n",
    "    global image_list\n",
    "    image_list_jpg = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.jpg' in f.lower()]\n",
    "    image_list_png = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.png' in f.lower()]\n",
    "    image_list = image_list_jpg + image_list_png\n",
    "\n",
    "    global x_images_dataset\n",
    "    x_images_dataset = np.zeros((len(image_list),new_h,new_w,3), dtype='uint8')\n",
    "    \n",
    "    global x_images_dataset_gray\n",
    "    x_images_dataset_gray = np.zeros((len(image_list),new_h,new_w), dtype='uint8')\n",
    "    \n",
    "    global x_images_dataset_edge\n",
    "    x_images_dataset_edge = np.zeros((len(image_list),new_h,new_w,1))\n",
    "    \n",
    "    \n",
    "    # 1.1 sanity assertion\n",
    "    # -------------------\n",
    "    assert len(image_list) > 0, 'No images in the folder'\n",
    "    \n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5) \n",
    "    pool.map(create_dataset_from_folder_single, list(range(len(image_list))))\n",
    "    \n",
    "    # 2.1 sanity assert\n",
    "    # -----------------\n",
    "    assert x_images_dataset.shape[0] == x_images_dataset_gray.shape[0], 'RGB and Grayscale images have different numbers of images!'\n",
    "    \n",
    "    # 3. filtering out the dataset\n",
    "    # ----------------------------\n",
    "    #print('Len at start: ' + str(x_images_dataset.shape))\n",
    "    x_images_dataset = x_images_dataset[index_list]\n",
    "    x_images_dataset_gray = x_images_dataset_gray[index_list]\n",
    "    x_images_dataset_edge = x_images_dataset_edge[index_list]\n",
    "    \n",
    "    \n",
    "    # hard normalising grayscale dataset by individual means\n",
    "    # ------------------------------------------------------\n",
    "    if gray_mode == 'bw':\n",
    "        \n",
    "        # hard b/w single channel\n",
    "        # -----------------------        \n",
    "        mn = np.mean(np.mean(x_images_dataset_gray, axis = 1), axis = 1)\n",
    "        mn = mn.reshape(mn.shape[0],1,1)\n",
    "        x_images_dataset_gray[x_images_dataset_gray < mn] = 0\n",
    "        x_images_dataset_gray[x_images_dataset_gray >= mn] = 255\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "    elif gray_mode == 'gray_3':\n",
    "        \n",
    "        # grayscale 3 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        x_images_dataset_gray = np.concatenate((x_images_dataset_gray,x_images_dataset_gray,x_images_dataset_gray), axis= 3)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # grayscale 1 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "\n",
    "    #print('Len after filtering: ' + str(x_images_dataset.shape))\n",
    "    print('Done creating dataset of around ' + str(counter) + ' images. Access them at global x_images_dataset, x_images_dataset_gray, x_images_dataset_edge.')\n",
    "    \n",
    "    # closing pools\n",
    "    # -------------\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "\n",
    "def create_dataset_from_folder_single(i):\n",
    "    \n",
    "    # 0. calling global variables\n",
    "    # ---------------------------\n",
    "    global gb_in_folder\n",
    "    global counter\n",
    "    global new_h\n",
    "    global new_w\n",
    "    global x_images_dataset\n",
    "    global x_images_dataset_gray\n",
    "    global image_list\n",
    "    global resize_flag\n",
    "    global x_images_dataset_edge\n",
    "    \n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    try:\n",
    "        name = image_list[i]\n",
    "        img_main = cv2.imread(join(gb_in_folder, name))\n",
    "        img = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2RGB)\n",
    "        img_gray = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # resizing ops\n",
    "        # -----------\n",
    "        if resize_flag == True:\n",
    "            img = cv2.resize(img, (new_w,new_h))\n",
    "            img_gray = cv2.resize(img_gray, (new_w,new_h))\n",
    "            \n",
    "\n",
    "        # 5. by default building edge images\n",
    "        # ----------------------------------\n",
    "        blurred = cv2.GaussianBlur(img_gray.reshape(new_h,new_w).astype('uint8'), (7, 7), 0)\n",
    "        edged = cv2.Canny(blurred, 50, 150)\n",
    "        edged = edged.reshape(new_h,new_w,1)\n",
    "        \n",
    "        # final assignments\n",
    "        # ------------------\n",
    "        x_images_dataset[i] = img\n",
    "        x_images_dataset_gray[i] = img_gray\n",
    "        x_images_dataset_edge[i] = edged\n",
    "        \n",
    "        counter += 1\n",
    "        index_list.append(i)\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        # do nothing\n",
    "        ##\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple forward pass function\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "def simple_forward_pass_pool(use_pretrained_in,xin,input_is_image,model):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    global use_pretrained_in_func\n",
    "    use_pretrained_in_func = use_pretrained_in\n",
    "    \n",
    "    global model_global\n",
    "    model_global = model\n",
    "    \n",
    "    global x_in_global\n",
    "    x_in_global = copy.deepcopy(xin)\n",
    "    \n",
    "    # 1. setting up y_out size\n",
    "    # ------------------------\n",
    "    global y_out_global\n",
    "    if use_pretrained_in == True:\n",
    "        sz = list(model(pre_process_pretrained_model_data(xin[0:2])).size())\n",
    "    else:\n",
    "        sz = list(model(xin[0:2]).size())\n",
    "    final_size = sz[1:]\n",
    "    final_size = tuple([xin.size()[0]] + final_size)\n",
    "    y_out_global = torch.zeros((final_size))\n",
    "    \n",
    "    \n",
    "    # 1.1 sanity\n",
    "    # ----------\n",
    "    if input_is_image == True:\n",
    "        assert torch.mean(x_in_global) > 1, 'Error: Data already in 0-1 range'\n",
    "        if use_pretrained_in == False:\n",
    "            x_in_global = x_in_global/torch.max(x_in_global)\n",
    "        \n",
    "    \n",
    "    # 2. calling pool function\n",
    "    # ------------------------\n",
    "    pool = ThreadPool(10)\n",
    "    pool.map(simple_forward_pass_single, list(range(xin.size()[0])))\n",
    "    #print('Done with forward pass of around ' + str(xin.size()[0]) + ' examples. Access them at global y_out_global.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def simple_forward_pass_single(i):\n",
    "    \n",
    "    # 0. global inits\n",
    "    # ---------------\n",
    "    global model_global\n",
    "    global x_in_global\n",
    "    global y_out_global\n",
    "    global use_pretrained_in_func\n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    curr_example = x_in_global[i]\n",
    "    curr_example = curr_example.view(1,curr_example.size()[0],curr_example.size()[1],curr_example.size()[2])\n",
    "    if use_pretrained_in_func == True:\n",
    "        curr_out = model_global(pre_process_pretrained_model_data(curr_example))\n",
    "    else:\n",
    "        curr_out = model_global(curr_example)\n",
    "    y_out_global[i] = curr_out[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to simply return similar images based on whole latents\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def similarity(input_latents_list,db_latents_list,xin,xdb,sim_weights,no_suggestions,similarity_check_mode,print_result):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. input includes\n",
    "    \n",
    "    a. input images & db images latent lists\n",
    "    b. settings such as weights, mode etc\n",
    "    c. will return indices of db images sorted in descending order of ranking similarity\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. initialisations\n",
    "    # ------------------\n",
    "    interim_sim_array = {}\n",
    "    final_sim_array = {}\n",
    "    final_all_indices = []\n",
    "    similar_products = []\n",
    "    all_similarity_values = []\n",
    "    epsilon = 0.0001\n",
    "    \n",
    "    # 2. sanity assertions\n",
    "    # --------------------\n",
    "    assert len(input_latents_list) == len(db_latents_list), 'Error: length of input & db lists dont match.'\n",
    "    if sim_weights == 'equal':\n",
    "        \n",
    "        # setting sim weight values to 1\n",
    "        # ------------------------------\n",
    "        sim_weights = []\n",
    "        for _ in range(len(input_latents_list)):\n",
    "            sim_weights.append(1.0)\n",
    "    else:\n",
    "        assert len(sim_weights) == len(input_latents_list), 'Error: number of weights & length of latent lists dont match.'\n",
    "        #assert round(sum(sim_weights),2) == 1.0, 'Error: the weights dont sum to 1.0'\n",
    "    \n",
    "    # 3. looping through the INPUT latents list\n",
    "    # -----------------------------------------\n",
    "    print('1. looping through latent list..')\n",
    "    for l_counter in range(len(input_latents_list)):\n",
    "        \n",
    "        # 3.0 local initialisations\n",
    "        # -------------------------\n",
    "        curr_input_latent = input_latents_list[l_counter]\n",
    "        db_input_latent = db_latents_list[l_counter]\n",
    "        \n",
    "        \n",
    "        # 3.1 itering through every image in curr_input_latent\n",
    "        # ----------------------------------------------------\n",
    "        for i in range(curr_input_latent.shape[0]):\n",
    "            \n",
    "            # Finding similarity per example\n",
    "            # ------------------------------\n",
    "            curr_input_latent_example = curr_input_latent[i]\n",
    "            \n",
    "            \n",
    "            # checking using similarity\n",
    "            # -------------------------\n",
    "            if similarity_check_mode == 'l2':\n",
    "                \n",
    "                # using L2\n",
    "                # --------\n",
    "                similarity_array = np.sqrt(np.sum((curr_input_latent_example-db_input_latent)**2, axis = 1))\n",
    "                \n",
    "                \n",
    "            elif similarity_check_mode == 'cosine_ratio':\n",
    "                \n",
    "                # using cosine_ratio\n",
    "                # ------------------\n",
    "                curr_input_latent_example = curr_input_latent_example.reshape(1,curr_input_latent_example.shape[0])\n",
    "                similarity_array = cosine_similarity_multi(curr_input_latent_example,db_input_latent)\n",
    "                similarity_array = similarity_array.reshape(similarity_array.shape[0],)\n",
    "                similarity_array += np.average((np.minimum(curr_input_latent_example,db_input_latent)/(np.maximum(curr_input_latent_example,db_input_latent) + epsilon)), axis = 1)\n",
    "            \n",
    "            \n",
    "            elif similarity_check_mode == 'cosine':\n",
    "                \n",
    "                # using cosine_ratio\n",
    "                # ------------------\n",
    "                curr_input_latent_example = curr_input_latent_example.reshape(1,curr_input_latent_example.shape[0])\n",
    "                similarity_array = cosine_similarity_multi(curr_input_latent_example,db_input_latent)\n",
    "                similarity_array = similarity_array.reshape(similarity_array.shape[0],)\n",
    "                \n",
    "            \n",
    "            \n",
    "            elif similarity_check_mode == 'ratio':\n",
    "                \n",
    "                # ratio only\n",
    "                # ----------\n",
    "                similarity_array = np.average((np.minimum(curr_input_latent_example,db_input_latent)/(np.maximum(curr_input_latent_example,db_input_latent) + epsilon)), axis = 1)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # invalid sim check mode\n",
    "                # ----------------------\n",
    "                assert 1 == 2, 'Error: invalid similarity check mode. This can be either \"cosine_ratio\" or \"ratio\" only.'\n",
    "            \n",
    "            \n",
    "            # appending to interim sim array for final weights application\n",
    "            # ------------------------------------------------------------\n",
    "            \n",
    "            # this dict will store all similarity values per example\n",
    "            # that is - \n",
    "            # interim_sim_array[0] = [sim_array_based_on_latent_list_0, sim_array_based_on_latent_list_1,...]\n",
    "            \n",
    "            try:\n",
    "                interim_sim_array[i].append(similarity_array)\n",
    "            except:\n",
    "                interim_sim_array[i] = []\n",
    "                interim_sim_array[i].append(similarity_array)\n",
    "    \n",
    "    \n",
    "    # 4. itering thru dict & applying weights\n",
    "    # ---------------------------------------\n",
    "    print('2. applying weights & appending final results..')\n",
    "    for keys in interim_sim_array:\n",
    "        \n",
    "        # deleting old value\n",
    "        # ------------------\n",
    "        try:\n",
    "            del similarity_array_final\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # itering thru list\n",
    "        # -----------------\n",
    "        for each_sim_array_index in range(len(interim_sim_array[keys])):\n",
    "            curr_weighted_array = interim_sim_array[keys][each_sim_array_index] * sim_weights[each_sim_array_index]\n",
    "            try:\n",
    "                similarity_array_final += curr_weighted_array\n",
    "            except:\n",
    "                similarity_array_final = curr_weighted_array\n",
    "                \n",
    "                \n",
    "        # similarity_array_final must be of shape (m,)\n",
    "        ###\n",
    "        \n",
    "        # continuation - no change here on\n",
    "        # --------------------------------\n",
    "        if similarity_check_mode == 'l2':\n",
    "            \n",
    "            # since in l2 distances are calculated and smaller dis = higher sim\n",
    "            # ------------------------------------------------------------------\n",
    "            sorted_indices = list(np.argsort(similarity_array_final))\n",
    "            \n",
    "        else:\n",
    "            sorted_indices = list(np.argsort(-1*similarity_array_final))\n",
    "        final_indices = sorted_indices[0:no_suggestions]\n",
    "        final_indices = [int(fi) for fi in final_indices]\n",
    "        final_all_indices.append(final_indices)\n",
    "        all_similarity_values.append(similarity_array[final_indices])\n",
    "        similar_products.append(xdb[final_indices])\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    # 3. showing if required\n",
    "    # ----------------------\n",
    "    if print_result == True:\n",
    "        \n",
    "        # itering\n",
    "        # -------\n",
    "        for i in range(xin.shape[0]):\n",
    "            \n",
    "            print('>> At image ' + str(i) + ' of around ' + str(xin.shape[0]) + '..')\n",
    "            print('** Input Image - ')\n",
    "            plt.figure(figsize=(2,2))\n",
    "            plt.imshow(xin[i])\n",
    "            plt.show()\n",
    "           \n",
    "            print('** Showing result images..')\n",
    "            fig=plt.figure(figsize=(25, 25))\n",
    "            columns = 5\n",
    "            rows = 10\n",
    "            \n",
    "            \n",
    "            for i_1 in range(similar_products[i].shape[0]):\n",
    "                \n",
    "                #print('** At image ' + str(i) + ' showing option number ' + str(i_1) + '**')\n",
    "                #print('Image index number: ' + str(final_all_indices[i][i_1]))\n",
    "                #print('Similarity value: ' + str(all_similarity_values[i][i_1]))\n",
    "                \n",
    "                if xdb.shape[3] > 1:\n",
    "                    img = similar_products[i][i_1]\n",
    "                    fig.add_subplot(rows, columns, i_1+1)\n",
    "                    plt.imshow(img)\n",
    "                    #plt.show()\n",
    "                else:\n",
    "                    img = similar_products[i][i_1,:,:,0]\n",
    "                    fig.add_subplot(rows, columns, i_1+1)\n",
    "                    plt.imshow(img, cmap='gray')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            print('\\n#########################################\\n')\n",
    "                \n",
    "            \n",
    "    \n",
    "    # 3. final return\n",
    "    # ---------------\n",
    "    return similar_products,all_similarity_values,final_all_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up all the variables here\n",
    "# -----------------------------\n",
    "img_h, img_w = 224,224\n",
    "use_cuda = False\n",
    "use_pretrained = True\n",
    "model_path = '/Users/venkateshmadhava/Documents/pmate2/pmate2_env/models/resnet50_pretrained_poc_5_class_GRAY_bird_apple_fish_skull_star_imgaug_and_text_aug.tar'\n",
    "db_folder = '/Users/venkateshmadhava/Desktop/temp_db'\n",
    "input_folder = '/Users/venkateshmadhava/Desktop/temp_input'\n",
    "\n",
    "# global variable class labels -- DO NOT CHANGE ORDER AS MODEL PREDICTIONS ARE DEPENDENT\n",
    "# --------------------------------------------------------------------------------------\n",
    "global class_labels\n",
    "class_labels = ['Bird','Apples','Fish','Skulls','Star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# --------------\n",
    "model_mimgcls,_,_,_,_ = load_saved_model_function(model_path, use_cuda)\n",
    "model_mimgcls = model_mimgcls.eval()\n",
    "\n",
    "# setting up latent if using pretrained\n",
    "# -------------------------------------\n",
    "if use_pretrained == True:\n",
    "    \n",
    "    # slicing FC to get latent\n",
    "    # ------------------------\n",
    "    model_mimgcls_for_latent = copy.deepcopy(model_mimgcls)\n",
    "    model_mimgcls_for_latent.fc = model_mimgcls_for_latent.fc[0:3]\n",
    "else:\n",
    "    \n",
    "    # incase we use a custom model, latent will be defined in it\n",
    "    # ----------------------------------------------------------\n",
    "    model_mimgcls_for_latent = model_mimgcls.latent\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. loading data & extracting feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 db data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading DB data\n",
    "# ---------------\n",
    "\n",
    "create_dataset_from_folder_all(db_folder,True,None,img_h,img_w)\n",
    "global x_images_dataset_gray\n",
    "x_db_cls_trn = Variable(setup_image_tensor(x_images_dataset_gray)).float()\n",
    "x_db_rgb = x_images_dataset\n",
    "print(x_db_cls_trn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction\n",
    "# ----------\n",
    "\n",
    "# 1. getting prediction\n",
    "# ---------------------   \n",
    "simple_forward_pass_pool(use_pretrained,x_db_cls_trn,True,model_mimgcls)\n",
    "global y_out_global\n",
    "db_pred = y_out_global\n",
    "del y_out_global\n",
    "\n",
    "# sanity\n",
    "# ------\n",
    "print(db_pred.size())\n",
    "\n",
    "# 2. getting latent\n",
    "# -----------------\n",
    "simple_forward_pass_pool(use_pretrained,x_db_cls_trn,True,model_mimgcls_for_latent)\n",
    "global y_out_global\n",
    "db_pred_latent = y_out_global\n",
    "del y_out_global\n",
    "\n",
    "# sanity\n",
    "# ------\n",
    "print(db_pred_latent.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 input queries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading input queries data\n",
    "# ---------------------------\n",
    "\n",
    "create_dataset_from_folder_all(input_folder,True,None,img_h,img_w)\n",
    "global x_images_dataset_gray\n",
    "x_input_cls_trn = Variable(setup_image_tensor(x_images_dataset_gray)).float()\n",
    "x_input_rgb = x_images_dataset\n",
    "print(x_input_cls_trn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction\n",
    "# ----------\n",
    "\n",
    "# 1. getting prediction\n",
    "# ---------------------   \n",
    "simple_forward_pass_pool(use_pretrained,x_input_cls_trn,True,model_mimgcls)\n",
    "global y_out_global\n",
    "input_pred = y_out_global\n",
    "del y_out_global\n",
    "\n",
    "# sanity\n",
    "# ------\n",
    "print(input_pred.size())\n",
    "\n",
    "# 2. getting latent\n",
    "# -----------------\n",
    "simple_forward_pass_pool(use_pretrained,x_input_cls_trn,True,model_mimgcls_for_latent)\n",
    "global y_out_global\n",
    "input_pred_latent = y_out_global\n",
    "del y_out_global\n",
    "\n",
    "# sanity\n",
    "# ------\n",
    "print(input_pred_latent.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 setting up latent list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final inputs to similarity function\n",
    "# -----------------------------------\n",
    "\n",
    "db_latents_list = [db_pred.detach().data.numpy(), db_pred_latent.detach().data.numpy()]\n",
    "input_latents_list = [input_pred.detach().data.numpy(),input_pred_latent.detach().data.numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up weightages of input latents lists\n",
    "# [1,1] means equal weightage for similarity between all vectors in the list\n",
    "# ---------------------------------------------------------------------------\n",
    "sim_w = [1,1]\n",
    "\n",
    "# actual function\n",
    "# ---------------\n",
    "_ = similarity(input_latents_list,db_latents_list,x_input_rgb,x_db_rgb,sim_w,50,'cosine',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
