{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a simple clustering algo\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Necessary imports - done\n",
    "# ------------------------\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import h5py\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "from __future__ import print_function\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# scipy related\n",
    "# -------------\n",
    "import scipy\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import filters\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "# necessary imports\n",
    "# -----------------\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "\n",
    "# working now\n",
    "# -----------\n",
    "#import skimage.io\n",
    "#from skimage.transform import rotate, AffineTransform, warp\n",
    "#from skimage.util import random_noise\n",
    "#from skimage.filters import gaussian\n",
    "#from skimage import transform as tf\n",
    "\n",
    "\n",
    "# neccessary imports for imgaug\n",
    "# ------------------------------\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "###\n",
    "###\n",
    "%matplotlib inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "\n",
    "\n",
    "# printing platform info\n",
    "# ----------------------\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC - change an torch image to numpy image\n",
    "# ----------------------------------------------\n",
    "def to_numpy_image(xin):\n",
    "    \n",
    "    try:\n",
    "        xin = xin.data.numpy()\n",
    "    except:\n",
    "        xin = xin.numpy()\n",
    "    \n",
    "    xout = np.swapaxes(xin,1,2)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped numpy images\n",
    "    # ---------------------------------\n",
    "    return xout       \n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - converts numpy images to torch tensors for training\n",
    "# -------------------------------------------------------------\n",
    "def setup_image_tensor(xin):\n",
    "    xout = np.swapaxes(xin,1,3)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped torch tensor\n",
    "    # ---------------------------------\n",
    "    xout = torch.from_numpy(xout)\n",
    "    return xout.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple non pool function that takes in main dict and indices\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def save_cluster_imgs_pool(out_folder_in,index_list_in,name_index_in):\n",
    "    \n",
    "    # 0. inits\n",
    "    # --------\n",
    "    global name_index\n",
    "    name_index = name_index_in\n",
    "    \n",
    "    global index_list\n",
    "    index_list = index_list_in\n",
    "    \n",
    "    global out_folder\n",
    "    out_folder = out_folder_in\n",
    "    \n",
    "    # 2. calling pool function\n",
    "    # ------------------------\n",
    "    pool = ThreadPool(10)\n",
    "    pool.map(save_cluster_imgs_single, list(range(len(index_list_in))))\n",
    "    print('Done with function save.')\n",
    "    \n",
    "    # closing pools\n",
    "    # -------------\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "def save_cluster_imgs_single(i):\n",
    "    \n",
    "    # calling globals\n",
    "    # ---------------\n",
    "    global name_index\n",
    "    global index_list\n",
    "    global out_folder\n",
    "    global x_dict_out\n",
    "    \n",
    "    # saving\n",
    "    # ------\n",
    "    img_name = out_folder + '/' + name_index + '_' + str(i) + '.jpg'\n",
    "    Image.fromarray(x_dict_out[index_list[i]]).save(img_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cluster_to_folder(cluster_labels,no_images,save_folder,name):\n",
    "    \n",
    "    # a simple loop\n",
    "    # -------------\n",
    "    for c in range(np.max(cluster_labels)+1):\n",
    "        \n",
    "        # creating cluster list\n",
    "        # ---------------------\n",
    "        curr_clus_inds = list(np.argwhere(clustering.labels_==c)[:,0])\n",
    "        curr_clus_inds = curr_clus_inds[0:no_images]\n",
    "        \n",
    "        # calling save function\n",
    "        # ---------------------\n",
    "        save_cluster_imgs_pool(save_folder,curr_clus_inds,name+'_cluster_'+str(c))\n",
    "        \n",
    "        print('done with current cluster: ' + str(c) + ' of ' + str(np.max(clustering.labels_)+1) + ' clusters..')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load a saved model\n",
    "# --------------------------------\n",
    "\n",
    "def load_saved_model_function(path, use_cuda):\n",
    "    \n",
    "    \n",
    "    ''' path = /folder1/folder2/model_ae.tar format'''\n",
    "    \n",
    "    # 1. loading full model\n",
    "    # ---------------------\n",
    "    model = torch.load(path.replace('.tar','_MODEL.tar'))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "    \n",
    "    # 2. Applying state dict\n",
    "    # ----------------------\n",
    "    if use_cuda == True:\n",
    "        \n",
    "        # loads to GPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "    else:\n",
    "        # loads to CPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        \n",
    "    # loading checkpoint\n",
    "    # -------------------\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # loading optimizer\n",
    "    # -----------------\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if use_cuda == True:\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # loading other stuff\n",
    "    # -------------------\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    loss_mode = checkpoint['loss_mode']\n",
    "    \n",
    "    return model, optimizer, epoch, loss, loss_mode\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to read a single image\n",
    "# --------------------------------------\n",
    "\n",
    "def create_dataset_from_folder_all(infolder,resize,gray_mode,n_h,n_w):\n",
    "    \n",
    "    # 0. global initialisations\n",
    "    # -------------------------\n",
    "    global x_dict\n",
    "    x_dict = {}\n",
    "    \n",
    "    global index_list\n",
    "    index_list = []\n",
    "    \n",
    "    global resize_flag\n",
    "    resize_flag = resize\n",
    "    \n",
    "    global gb_in_folder\n",
    "    gb_in_folder = infolder\n",
    "\n",
    "    global counter\n",
    "    counter = 0\n",
    "    \n",
    "    global new_h\n",
    "    new_h = n_h\n",
    "    \n",
    "    global new_w\n",
    "    new_w = n_w\n",
    "    \n",
    "    global image_list\n",
    "    image_list_jpg = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.jpg' in f.lower()]\n",
    "    image_list_png = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.png' in f.lower()]\n",
    "    image_list = image_list_jpg + image_list_png\n",
    "\n",
    "    global x_images_dataset\n",
    "    x_images_dataset = np.zeros((len(image_list),new_h,new_w,3), dtype='uint8')\n",
    "    \n",
    "    global x_images_dataset_gray\n",
    "    x_images_dataset_gray = np.zeros((len(image_list),new_h,new_w), dtype='uint8')\n",
    "    \n",
    "    global x_images_dataset_edge\n",
    "    x_images_dataset_edge = np.zeros((len(image_list),new_h,new_w,1))\n",
    "    \n",
    "    \n",
    "    # 1.1 sanity assertion\n",
    "    # -------------------\n",
    "    assert len(image_list) > 0, 'No images in the folder'\n",
    "    \n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5) \n",
    "    pool.map(create_dataset_from_folder_single, list(range(len(image_list))))\n",
    "    \n",
    "    # 2.1 sanity assert\n",
    "    # -----------------\n",
    "    assert x_images_dataset.shape[0] == x_images_dataset_gray.shape[0], 'RGB and Grayscale images have different numbers of images!'\n",
    "    \n",
    "    # 3. filtering out the dataset\n",
    "    # ----------------------------\n",
    "    print('Len at start: ' + str(x_images_dataset.shape))\n",
    "    x_images_dataset = x_images_dataset[index_list]\n",
    "    x_images_dataset_gray = x_images_dataset_gray[index_list]\n",
    "    x_images_dataset_edge = x_images_dataset_edge[index_list]\n",
    "    \n",
    "    # 4. index correcting dict\n",
    "    # ------------------------\n",
    "    global x_dict_out\n",
    "    x_dict_out = {}\n",
    "    for i in range(len(index_list)):\n",
    "        x_dict_out[i] = x_dict[index_list[i]]\n",
    "        \n",
    "    \n",
    "    \n",
    "    # hard normalising grayscale dataset by individual means\n",
    "    # ------------------------------------------------------\n",
    "    if gray_mode == 'bw':\n",
    "        \n",
    "        # hard b/w single channel\n",
    "        # -----------------------        \n",
    "        mn = np.mean(np.mean(x_images_dataset_gray, axis = 1), axis = 1)\n",
    "        mn = mn.reshape(mn.shape[0],1,1)\n",
    "        x_images_dataset_gray[x_images_dataset_gray < mn] = 0\n",
    "        x_images_dataset_gray[x_images_dataset_gray >= mn] = 255\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "    elif gray_mode == 'gray_3':\n",
    "        \n",
    "        # grayscale 3 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        x_images_dataset_gray = np.concatenate((x_images_dataset_gray,x_images_dataset_gray,x_images_dataset_gray), axis= 3)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # grayscale 1 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "\n",
    "    print('Len after filtering: ' + str(x_images_dataset.shape))\n",
    "    print('Done creating dataset of around ' + str(counter) + ' images. Access them at global x_images_dataset, x_images_dataset_gray, x_images_dataset_edge, x_dict_out.')\n",
    "    \n",
    "    # closing pools\n",
    "    # -------------\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "\n",
    "def create_dataset_from_folder_single(i):\n",
    "    \n",
    "    # 0. calling global variables\n",
    "    # ---------------------------\n",
    "    global gb_in_folder\n",
    "    global counter\n",
    "    global new_h\n",
    "    global new_w\n",
    "    global x_images_dataset\n",
    "    global x_images_dataset_gray\n",
    "    global image_list\n",
    "    global resize_flag\n",
    "    global x_images_dataset_edge\n",
    "    global x_dict\n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    try:\n",
    "        name = image_list[i]\n",
    "        img_main = cv2.imread(join(gb_in_folder, name))\n",
    "        img_main_rbg = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2RGB)\n",
    "        img_gray = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # resizing ops\n",
    "        # -----------\n",
    "        if resize_flag == True:\n",
    "            img = cv2.resize(img, (new_w,new_h))\n",
    "            img_gray = cv2.resize(img_gray, (new_w,new_h))\n",
    "            \n",
    "\n",
    "        # 5. by default building edge images\n",
    "        # ----------------------------------\n",
    "        blurred = cv2.GaussianBlur(img_gray.reshape(new_h,new_w).astype('uint8'), (7, 7), 0)\n",
    "        edged = cv2.Canny(blurred, 50, 150)\n",
    "        edged = edged.reshape(new_h,new_w,1)\n",
    "        \n",
    "        # final assignments\n",
    "        # ------------------\n",
    "        x_images_dataset[i] = img\n",
    "        x_images_dataset_gray[i] = img_gray\n",
    "        x_images_dataset_edge[i] = edged\n",
    "        \n",
    "        counter += 1\n",
    "        index_list.append(i)\n",
    "        x_dict[i] = img_main_rbg\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        # do nothing\n",
    "        ##\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple forward pass function\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "def simple_forward_pass_pool(xin,input_is_image,model):\n",
    "    \n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    global model_global\n",
    "    model_global = model\n",
    "    \n",
    "    global x_in_global\n",
    "    x_in_global = copy.deepcopy(xin)\n",
    "    \n",
    "    # 1. setting up y_out size\n",
    "    # ------------------------\n",
    "    global y_out_global\n",
    "    sz = list(model(xin[0:2]).size())\n",
    "    final_size = sz[1:]\n",
    "    final_size = tuple([xin.size()[0]] + final_size)\n",
    "    y_out_global = torch.zeros((final_size))\n",
    "    \n",
    "    \n",
    "    # 1.1 sanity\n",
    "    # ----------\n",
    "    if input_is_image == True:\n",
    "        assert torch.mean(x_in_global) > 1, 'Error: Data already in 0-1 range'\n",
    "        x_in_global = x_in_global/torch.max(x_in_global)\n",
    "        \n",
    "    \n",
    "    # 2. calling pool function\n",
    "    # ------------------------\n",
    "    pool = ThreadPool(10)\n",
    "    pool.map(simple_forward_pass_single, list(range(xin.size()[0])))\n",
    "    print('Done with forward pass of around ' + str(xin.size()[0]) + ' examples. Access them at global y_out_global.')\n",
    "    \n",
    "    # closing pools\n",
    "    # -------------\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "    \n",
    "def simple_forward_pass_single(i):\n",
    "    \n",
    "    # 0. global inits\n",
    "    # ---------------\n",
    "    global model_global\n",
    "    global x_in_global\n",
    "    global y_out_global\n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    curr_example = x_in_global[i]\n",
    "    curr_example = curr_example.view(1,curr_example.size()[0],curr_example.size()[1],curr_example.size()[2])\n",
    "    curr_out = model_global(curr_example)\n",
    "    y_out_global[i] = curr_out[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will return final latents for similarity function \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def final_latents(f_maps,kernel_stride_dims,pool_mode,aggregate_pool_maps):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. input is a dict with keys - \n",
    "    \n",
    "    a. f_maps - list of feature maps (m,c,h,w) on which pooling functions can be run for latent computation\n",
    "    b. kernel_dims - list of kernel dimensions that will be used for pooling on feature maps\n",
    "    c. pool_mode - 'max', 'avg' or 'both'\n",
    "    d. aggregate_pool_maps - either sum up pool values or not\n",
    "    \n",
    "    2. output will be a dict with final latents to be input to similarity function\n",
    "    3. output latents will be L2 normalized\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    latents_out = []\n",
    "    \n",
    "    \n",
    "    # 1. computing rmac latents\n",
    "    # -------------------------\n",
    "    for each_fmap in f_maps:\n",
    "        for each_kernel_dim in kernel_stride_dims:\n",
    "            curr_latent = return_ms_rmac([each_fmap],pool_mode,each_kernel_dim,aggregate_pool_maps).data.numpy()\n",
    "            \n",
    "            # L2 normalization\n",
    "            # ----------------\n",
    "            #curr_latent = curr_latent / np.linalg.norm(curr_latent)\n",
    "            \n",
    "            # appending\n",
    "            # ----------\n",
    "            latents_out.append(curr_latent)\n",
    "            print('done at kernel ' + str(each_kernel_dim) + '. latent size: ' + str(curr_latent.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return latents_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "# -------------\n",
    "\n",
    "def return_ms_rmac(fmaps_list,pool_mode,kernel_dims,aggregate_pool_maps):\n",
    "    \n",
    "    '''\n",
    "    ref: https://www.researchgate.net/publication/313465134_MS-RMAC_Multiscale_Regional_Maximum_Activation_of_Convolutions_for_Image_Retrieval\n",
    "    \n",
    "    1. takes as input fmaps tuple with feature masps of size (m,k,h,w) each where k = no_channels at each layer\n",
    "    -- input is ((m1,k1,h1,w1), (m2,k2,h2,w2),...)\n",
    "    -- pool_mode = 'max','avg','both'\n",
    "    -- kernel_dims = None or (f,s)\n",
    "    -- aggregate_pool_maps - if true, we will sum across channels, else leave as it is\n",
    "    \n",
    "    2. works out 3 scales of MAC kernel sizes for each feature map in tuple\n",
    "    3. computes MAC i.e., maximum activations convolutions & aggregates them\n",
    "    4. returns concatenated (m,K) vector where K = k1 + k2 + k3.. i.e., no_channels at each layer in fmaps in tuple\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # -------------------\n",
    "    assert type(fmaps_list) == list, 'Type error: input feature maps must be a list'\n",
    "    \n",
    "    \n",
    "    # 1. looping through fmap tuple\n",
    "    # -----------------------------\n",
    "    for fmap in fmaps_list:\n",
    "        \n",
    "        # 1.1 checking kernel initialisations\n",
    "        # -----------------------------------\n",
    "        if kernel_dims == None:\n",
    "            \n",
    "            # 1.1.1 we will be using preset scaled regions - computing f,s\n",
    "            # ------------------------------------------------------------\n",
    "            h,w = fmap.size()[2],fmap.size()[3]\n",
    "\n",
    "            # scale 1 : w is same, h = h/2, stride = curr_h/3\n",
    "            ##\n",
    "            l1_h = int(h/2)\n",
    "            l1_w = w\n",
    "            l1_s = int(l1_h/2)\n",
    "\n",
    "            # scale 2 : h = h/2, w = 2w/3, stride = curr_w/2\n",
    "            ##\n",
    "            l2_h = int(h/2)\n",
    "            l2_w = int(2*w/3)\n",
    "            l2_s = int(l2_w/2)\n",
    "\n",
    "            # scale 3 : h = 2h/5, w = w/2, stride = curr_w/2\n",
    "            ##\n",
    "            l3_h = int(2*h/5)\n",
    "            l3_w = int(w/2)\n",
    "            l3_s = int(l3_w/2)\n",
    "            \n",
    "            \n",
    "            # 1.1.1.2 forward pass to get pool maps\n",
    "            # --------------------------------------\n",
    "            if pool_mode == 'max':\n",
    "                \n",
    "                # computing mx pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.MaxPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.MaxPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.MaxPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # -----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map\n",
    "                \n",
    "                \n",
    "            \n",
    "            elif pool_mode == 'avg':\n",
    "                \n",
    "\n",
    "                # computing avg pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.AvgPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.AvgPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.AvgPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # ----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map\n",
    "                \n",
    "                \n",
    "            elif pool_mode == 'both':\n",
    "                \n",
    "                # computing mx pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.MaxPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.MaxPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.MaxPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # computing avg pool @ scale 1\n",
    "                # ---------------------------\n",
    "                avg_pl_l1 =  nn.Sequential(*[nn.AvgPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                avg_l1_pool_map = avg_pl_l1(fmap)\n",
    "                avg_l1_pool_map = torch.sum(torch.sum(avg_l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 2\n",
    "                # ---------------------------\n",
    "                avg_pl_l2 =  nn.Sequential(*[nn.AvgPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                avg_l2_pool_map = avg_pl_l2(fmap)\n",
    "                avg_l2_pool_map = torch.sum(torch.sum(avg_l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 3\n",
    "                # ---------------------------\n",
    "                avg_pl_l3 =  nn.Sequential(*[nn.AvgPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                avg_l3_pool_map = avg_pl_l3(fmap)\n",
    "                avg_l3_pool_map = torch.sum(torch.sum(avg_l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # ----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map + avg_l1_pool_map + avg_l2_pool_map + avg_l3_pool_map\n",
    "\n",
    "            else:\n",
    "                \n",
    "                assert 1 == 2,'Error: invalid pool mode'\n",
    "                \n",
    "            \n",
    "            # 1.1.1.3 finally concatenating pool maps across all input feature maps\n",
    "            # ---------------------------------------------------------------------\n",
    "            try:\n",
    "                all_layers_pool_map = torch.cat((all_layers_pool_map,combined_pool_map), 1)\n",
    "            except:\n",
    "                all_layers_pool_map = combined_pool_map\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # if the input dims are given\n",
    "        # ---------------------------\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            # 1.1.2 dims is given as (f,s)\n",
    "            # ----------------------------\n",
    "            curr_f = kernel_dims[0]\n",
    "            curr_s = kernel_dims[1]\n",
    "            \n",
    "            # 1.1.2.1 setting up sequentials\n",
    "            # ------------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((curr_f,curr_f), stride=curr_s)])\n",
    "            avgpl =  nn.Sequential(*[nn.AvgPool2d((curr_f,curr_f), stride=curr_s)])\n",
    "            \n",
    "            \n",
    "            # 1.1.2.2 forward pass to get pool maps\n",
    "            # --------------------------------------\n",
    "            if pool_mode == 'max':\n",
    "                \n",
    "                # computing max pool\n",
    "                # ------------------\n",
    "                pool_map = mxpl(fmap)\n",
    "\n",
    "            \n",
    "            elif pool_mode == 'avg':\n",
    "                \n",
    "                # computing avg pool\n",
    "                # ------------------\n",
    "                pool_map = avgpl(fmap)\n",
    "            \n",
    "            elif pool_mode == 'both':\n",
    "                \n",
    "                # computing both\n",
    "                # --------------\n",
    "                mx_pool_map = mxpl(fmap)\n",
    "                avg_pool_map = avgpl(fmap)\n",
    "                \n",
    "                # concatenating\n",
    "                # -------------\n",
    "                #pool_map = torch.cat((mx_pool_map,avg_pool_map), 1)\n",
    "                pool_map = mx_pool_map + avg_pool_map\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                assert 1 == 2,'Error: invalid pool mode'\n",
    "            \n",
    "            \n",
    "            \n",
    "            # 1.1.2.3 aggregating\n",
    "            # -------------------\n",
    "            if aggregate_pool_maps == True:\n",
    "                \n",
    "                # summing along h,w axises - pool_map will be of shape (m,no_channels)\n",
    "                # --------------------------------------------------------------------\n",
    "                pool_map = torch.sum(torch.sum(pool_map, 2),2)\n",
    "                \n",
    "            \n",
    "            # final resize before concat\n",
    "            # --------------------------\n",
    "            pool_map = pool_map.view(pool_map.size()[0],-1)\n",
    "            \n",
    "            \n",
    "            # final concat along channel axis\n",
    "            # --------------------------------\n",
    "            try:\n",
    "                all_layers_pool_map = torch.cat((all_layers_pool_map,pool_map), 1)\n",
    "            except:\n",
    "                all_layers_pool_map = pool_map\n",
    "                \n",
    "\n",
    "    # final return\n",
    "    # ------------\n",
    "    return all_layers_pool_map\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_4_layer_std(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv #nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 512\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nn.Softmax2d()#nw_activation_conv #nn.Softmax2d() #nw_activation_conv\n",
    "        cl4 = [ct4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,in_channels,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "            \n",
    "        \n",
    "        return c4_out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_3_layer_std(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        #up_conv1 = 128\n",
    "        #t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        #b1 = nn.BatchNorm2d(up_conv1)\n",
    "        #a1 = nw_activation_conv\n",
    "        #l1 = [t1,b1,a1,dropout_node]\n",
    "        #self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(conv3,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,in_channels,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        #f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(c3_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        latent_out = self.convl3(c2_out)\n",
    "            \n",
    "        \n",
    "        return latent_out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF CODE\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL set ups for execution\n",
    "# -------------------------\n",
    "\n",
    "## SET UP CUDA OR NOT HERE + OTHER SET UPS\n",
    "##########################################\n",
    "\n",
    "dev_env = 'local' # 'gpu' or 'local'\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Setting CUDA\n",
    "# ------------\n",
    "if dev_env == 'gpu':\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False\n",
    "if use_cuda == True:\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "# SET FILE SPECIFIC NAMES HERE\n",
    "# ----------------------------\n",
    "if dev_env == 'gpu':\n",
    "    save_path = '/home/venkateshmadhava/codes/pmate2_localgpuenv/models/'\n",
    "    parent_url = '/home/venkateshmadhava/datasets/images'\n",
    "else:\n",
    "    save_path = '/Users/venkateshmadhava/Documents/pmate2/pmate2_env/models/'\n",
    "    parent_url = '/Users/venkateshmadhava/Documents/pmate2/local_working_files'\n",
    "\n",
    "\n",
    "# displaying save path\n",
    "# --------------------\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. creating dataset from folder\n",
    "# ------------------------------------\n",
    "in_folder = '/Users/venkateshmadhava/Documents/si_projects/datasets/si_dataset_1'\n",
    "\n",
    "\n",
    "# 1.1 creating dataset\n",
    "# --------------------\n",
    "create_dataset_from_folder_all(in_folder,True,'gray_3',175,175)\n",
    "global x_images_dataset, x_images_dataset_gray, x_images_dataset_edge\n",
    "\n",
    "\n",
    "# 1.2 main setups -- DO NOT CHANGE\n",
    "# --------------------------------\n",
    "use_grayscale = True\n",
    "use_edge = False\n",
    "if use_grayscale == True:\n",
    "    if use_edge == True:\n",
    "        xtest = x_images_dataset_edge\n",
    "    else:\n",
    "        xtest = x_images_dataset_gray\n",
    "else:\n",
    "    xtest = x_images_dataset\n",
    "\n",
    "    \n",
    "# 1.3 for printing view\n",
    "# ---------------------\n",
    "xtest_print = x_images_dataset\n",
    "\n",
    "\n",
    "# 1.4 sanity\n",
    "# ----------\n",
    "del x_images_dataset, x_images_dataset_gray, x_images_dataset_edge\n",
    "print(len(x_dict_out))\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sanity viewing DO THIS ALWAYS\n",
    "# ------------------------------\n",
    "\n",
    "randrange = random.sample(list(range(xtest.shape[0])), 2)\n",
    "\n",
    "for i in randrange:\n",
    "    print(i)\n",
    "    if use_grayscale == True:\n",
    "        plt.imshow(xtest[i,:,:,0],cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.imshow(xtest[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. loading model and checking reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading saved model\n",
    "# -------------------\n",
    "\n",
    "#torch.nn.Module.dump_patches = False\n",
    "cn_file_name = 'ae_model_tboard_3_layer_128_latent_gray_softmax.tar'#'ae_model_tboard_4_layer_512_softmax_RGB.tar'\n",
    "cn_save_path = save_path + cn_file_name\n",
    "model,_,_,_,_ = load_saved_model_function(cn_save_path, use_cuda)\n",
    "model = model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data\n",
    "# ---------------\n",
    "\n",
    "xtrn = Variable(setup_image_tensor(xtest[:,:,:,0:1])).float()\n",
    "print(xtrn.size())\n",
    "print(torch.mean(xtrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking reconstruction -- ALWAYS DO THIS\n",
    "# -----------------------------------------\n",
    "randrange = random.sample(list(range(xtrn.size()[0])), 2)\n",
    "recons = model.eval()(xtrn[randrange]/torch.max(xtrn[randrange]))\n",
    "recons = to_numpy_image(recons)\n",
    "\n",
    "\n",
    "# showing images\n",
    "# --------------\n",
    "for i in range(2):\n",
    "    \n",
    "    print('orig: ')\n",
    "    plt.imshow(xtest[randrange[i]])\n",
    "    plt.show()\n",
    "    print('recons: ')\n",
    "    plt.imshow(recons[i,:,:,0],cmap='gray')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. extracting feature maps & preparing latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting feature maps\n",
    "# -----------------------\n",
    "\n",
    "simple_forward_pass_pool(xtrn,True,model.latent)\n",
    "global y_out_global\n",
    "input_fmaps = y_out_global\n",
    "del y_out_global\n",
    "print(input_fmaps.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# LATENT SETTINGS #################\n",
    "###################################################\n",
    "\n",
    "# what works RGB -- RGB local - (1/3*h,1/3*w) i.e if h,w of fmap is 10,10 then local pool dim is 3,3\n",
    "\n",
    "# latents settings\n",
    "# ----------------\n",
    "kernel_stride_dims = [[5,2]]\n",
    "pool_mode = 'both'\n",
    "aggregate_pool_maps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing latents from fmaps\n",
    "# ----------------------------\n",
    "input_latents_list = final_latents([input_fmaps],kernel_stride_dims,pool_mode,aggregate_pool_maps)\n",
    "\n",
    "# final step before clustering\n",
    "# ----------------------------\n",
    "input_latents = input_latents_list[0]\n",
    "input_latents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for checking hyper params -- DO NOT DELETE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "#X = np.array([[1, 2], [1, 4], [1, 0],[4, 2], [4, 4], [4, 0]])\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main code for clustering -- use 1.5 as default\n",
    "# this will take time... approximately 2 minutes for a dataset of 1000 images\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "dist_threshold = np.mean(distance_matrix(input_latents,input_latents)) * 1.5\n",
    "clustering = AgglomerativeClustering(n_clusters=None,distance_threshold=dist_threshold,compute_full_tree=True).fit(input_latents)\n",
    "print('total clusters found: ' + str(np.max(clustering.labels_)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualising clusters\n",
    "# --------------------\n",
    "\n",
    "for c in range(np.max(clustering.labels_)+1):\n",
    "    \n",
    "    print('current cluster: ' + str(c))\n",
    "    curr_clus_inds = list(np.argwhere(clustering.labels_==c)[:,0])\n",
    "    print('no of images here: ' + str(len(curr_clus_inds)))\n",
    "    \n",
    "    \n",
    "    # just showing limted images\n",
    "    # --------------------------\n",
    "    fig=plt.figure(figsize=(30, 30)) # in format (r,c)\n",
    "    columns = 5\n",
    "    rows = 5\n",
    "    counter = 0\n",
    "\n",
    "    for each_ind in curr_clus_inds:\n",
    "        \n",
    "        counter += 1\n",
    "        fig.add_subplot(rows, columns, counter)\n",
    "        plt.imshow(xtest[each_ind])\n",
    "        \n",
    "        if counter == 25:\n",
    "            break\n",
    "    plt.show()\n",
    "    \n",
    "    print('*********************************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. saving to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final saving to an output folder\n",
    "# set save params here\n",
    "# ---------------------------------\n",
    "\n",
    "file_name_prefix = 'random_noise_si_dtset_2'\n",
    "max_no_images_per_cluster_to_save = 2\n",
    "out_folder = '/Users/venkateshmadhava/Desktop/tempp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for final save -- this will save \n",
    "# max_no_images_per_cluster_to_save number of images per cluster to the\n",
    "# out folder\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "save_cluster_to_folder(clustering.labels_,max_no_images_per_cluster_to_save,out_folder,file_name_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bird, dog, fish, star, leaves, sun, mountains, flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
