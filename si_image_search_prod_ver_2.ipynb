{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a notebook with all the dependencies required for image search\n",
    "##\n",
    "\n",
    "1. inputs - just the URL's of search query & DB images\n",
    "2. link up models\n",
    "3. run single function\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# -------\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import h5py\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# may not be required\n",
    "# -------------------\n",
    "#from __future__ import print_function\n",
    "#import scipy\n",
    "#from scipy.ndimage import filters\n",
    "#from scipy import misc\n",
    "#from io import BytesIO\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_image_tensor(xin):\n",
    "    xout = np.swapaxes(xin,1,3)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped torch tensor\n",
    "    # ---------------------------------\n",
    "    xout = torch.from_numpy(xout)\n",
    "    return xout.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_multi(a,b):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. a,b are of shape (m,no_latent)\n",
    "    2. output is of shape (m,1)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. direct steps\n",
    "    # ---------------\n",
    "    dot_prod = np.sum(a*b, axis = 1)\n",
    "    norm_a = np.sqrt(np.sum(np.square(a),axis = 1))\n",
    "    norm_b = np.sqrt(np.sum(np.square(b),axis = 1))\n",
    "    out = dot_prod/(norm_a*norm_b)\n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # -------------\n",
    "    return out.reshape(out.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load a saved model\n",
    "# --------------------------------\n",
    "\n",
    "def load_saved_model_function(path, use_cuda):\n",
    "    \n",
    "    \n",
    "    ''' path = /folder1/folder2/model_ae.tar format'''\n",
    "    \n",
    "    # 1. loading full model\n",
    "    # ---------------------\n",
    "    model = torch.load(path.replace('.tar','_MODEL.tar'))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "    \n",
    "    # 2. Applying state dict\n",
    "    # ----------------------\n",
    "    if use_cuda == True:\n",
    "        \n",
    "        # loads to GPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "    else:\n",
    "        # loads to CPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        \n",
    "    # loading checkpoint\n",
    "    # -------------------\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # loading optimizer\n",
    "    # -----------------\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if use_cuda == True:\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # loading other stuff\n",
    "    # -------------------\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    loss_mode = checkpoint['loss_mode']\n",
    "    \n",
    "    return model, optimizer, epoch, loss, loss_mode\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to extract feature maps\n",
    "# ----------------------------------\n",
    "\n",
    "def extract_feature_maps(images_url, use_gray_scale_images, model_url, use_cuda):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. takes as input folder url for images and the model\n",
    "    2. loads models and does a forward pass to extract features\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    h,w = 175,175 # do not change this\n",
    "    \n",
    "    # 1. creating dataset from in images folder\n",
    "    # -----------------------------------------\n",
    "    print('1. creating dataset..')\n",
    "    create_dataset_from_folder_all(images_url,True,'gray_3',h,w)\n",
    "    global x_images_dataset\n",
    "    global x_images_dataset_gray\n",
    "    x_input_rgb, x_input_gy = copy.deepcopy(x_images_dataset), copy.deepcopy(x_images_dataset_gray)\n",
    "    x_out = copy.deepcopy(x_input_rgb)\n",
    "    del x_images_dataset,x_images_dataset_gray\n",
    "    \n",
    "    # always show images for sanity purpose\n",
    "    # -------------------------------------\n",
    "    #plt.imshow(x_input_rgb[0])\n",
    "    #plt.show()\n",
    "    #plt.imshow(x_input_gy[0,:,:,0], cmap = 'gray')\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    # 2. dataset setup\n",
    "    # ----------------\n",
    "    if use_gray_scale_images == True:\n",
    "        \n",
    "        # this is a grayscale model\n",
    "        # -------------------------\n",
    "        del x_input_rgb\n",
    "        x_trn = Variable(setup_image_tensor(x_input_gy)).float()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # this is a RGB model\n",
    "        # -------------------\n",
    "        del x_input_gy\n",
    "        x_trn = Variable(setup_image_tensor(x_input_rgb)).float()\n",
    "        \n",
    "    \n",
    "    # 2. loading model and extracting features\n",
    "    # ----------------------------------------\n",
    "    print('2. loading model & extracting features..')\n",
    "    model,_,_,_,_ = load_saved_model_function(model_url, use_cuda)\n",
    "    model = model.eval()\n",
    "    \n",
    "    # 3. forward pass on model\n",
    "    # ------------------------\n",
    "    simple_forward_pass_pool(x_trn,True,model.latent)\n",
    "    global y_out_global\n",
    "    fmaps = y_out_global\n",
    "    del y_out_global\n",
    "    print('**')\n",
    "    print('Size of feature maps is: ' + str(fmaps.size()))\n",
    "    print('####\\n')\n",
    "    \n",
    "    \n",
    "    # 4. final return\n",
    "    # ---------------\n",
    "    return fmaps, x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to read a single image\n",
    "# --------------------------------------\n",
    "\n",
    "def create_dataset_from_folder_all(infolder,resize,gray_mode,n_h,n_w):\n",
    "    \n",
    "    # 0. global initialisations\n",
    "    # -------------------------\n",
    "    global index_list\n",
    "    index_list = []\n",
    "    \n",
    "    global resize_flag\n",
    "    resize_flag = resize\n",
    "    \n",
    "    global gb_in_folder\n",
    "    gb_in_folder = infolder\n",
    "\n",
    "    global counter\n",
    "    counter = 0\n",
    "    \n",
    "    global new_h\n",
    "    new_h = n_h\n",
    "    \n",
    "    global new_w\n",
    "    new_w = n_w\n",
    "    \n",
    "    global image_list\n",
    "    image_list_jpg = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.jpg' in f.lower()]\n",
    "    image_list_png = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.png' in f.lower()]\n",
    "    image_list = image_list_jpg + image_list_png\n",
    "\n",
    "    global x_images_dataset\n",
    "    x_images_dataset = np.zeros((len(image_list),new_h,new_w,3), dtype='uint8')\n",
    "    \n",
    "    global x_images_dataset_gray\n",
    "    x_images_dataset_gray = np.zeros((len(image_list),new_h,new_w), dtype='uint8')\n",
    "\n",
    "    \n",
    "    # 1.1 sanity assertion\n",
    "    # -------------------\n",
    "    assert len(image_list) > 0, 'No images in the folder'\n",
    "    \n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5) \n",
    "    pool.map(create_dataset_from_folder_single, list(range(len(image_list))))\n",
    "    \n",
    "    # 2.1 sanity assert\n",
    "    # -----------------\n",
    "    assert x_images_dataset.shape[0] == x_images_dataset_gray.shape[0], 'RGB and Grayscale images have different numbers of images!'\n",
    "    \n",
    "    # 3. filtering out the dataset\n",
    "    # ----------------------------\n",
    "    print('Len at start: ' + str(x_images_dataset.shape))\n",
    "    x_images_dataset = x_images_dataset[index_list]\n",
    "    x_images_dataset_gray = x_images_dataset_gray[index_list]\n",
    "    \n",
    "    \n",
    "    # hard normalising grayscale dataset by individual means\n",
    "    # ------------------------------------------------------\n",
    "    if gray_mode == 'bw':\n",
    "        \n",
    "        # hard b/w single channel\n",
    "        # -----------------------        \n",
    "        mn = np.mean(np.mean(x_images_dataset_gray, axis = 1), axis = 1)\n",
    "        mn = mn.reshape(mn.shape[0],1,1)\n",
    "        x_images_dataset_gray[x_images_dataset_gray < mn] = 0\n",
    "        x_images_dataset_gray[x_images_dataset_gray >= mn] = 255\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "    elif gray_mode == 'gray_3':\n",
    "        \n",
    "        # grayscale 3 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        x_images_dataset_gray = np.concatenate((x_images_dataset_gray,x_images_dataset_gray,x_images_dataset_gray), axis= 3)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # grayscale 1 channel\n",
    "        # -------------------\n",
    "        x_images_dataset_gray = x_images_dataset_gray.reshape(x_images_dataset_gray.shape[0],new_h,new_w,1)\n",
    "        \n",
    "\n",
    "    print('Len after filtering: ' + str(x_images_dataset.shape))\n",
    "    print('Done creating dataset of around ' + str(counter) + ' images. Access them at global x_images_dataset, x_images_dataset_gray.')\n",
    "\n",
    "    \n",
    "\n",
    "def create_dataset_from_folder_single(i):\n",
    "    \n",
    "    # 0. calling global variables\n",
    "    # ---------------------------\n",
    "    global gb_in_folder\n",
    "    global counter\n",
    "    global new_h\n",
    "    global new_w\n",
    "    global x_images_dataset\n",
    "    global x_images_dataset_gray\n",
    "    global image_list\n",
    "    global resize_flag\n",
    "    \n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    try:\n",
    "        name = image_list[i]\n",
    "        img_main = cv2.imread(join(gb_in_folder, name))\n",
    "        img = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2RGB)\n",
    "        img_gray = cv2.cvtColor(copy.deepcopy(img_main), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # resizing ops\n",
    "        # -----------\n",
    "        if resize_flag == True:\n",
    "            img = cv2.resize(img, (new_w,new_h))\n",
    "            img_gray = cv2.resize(img_gray, (new_w,new_h))\n",
    "            \n",
    "        x_images_dataset[i] = img\n",
    "        x_images_dataset_gray[i] = img_gray\n",
    "        \n",
    "        counter += 1\n",
    "        index_list.append(i)\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        # do nothing\n",
    "        ##\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple forward pass function\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "def simple_forward_pass_pool(xin,input_is_image,model):\n",
    "    \n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    global model_global\n",
    "    model_global = model\n",
    "    \n",
    "    global x_in_global\n",
    "    x_in_global = copy.deepcopy(xin)\n",
    "    \n",
    "    # 1. setting up y_out size\n",
    "    # ------------------------\n",
    "    global y_out_global\n",
    "    sz = list(model(xin[0:2]).size())\n",
    "    final_size = sz[1:]\n",
    "    final_size = tuple([xin.size()[0]] + final_size)\n",
    "    y_out_global = torch.zeros((final_size))\n",
    "    \n",
    "    \n",
    "    # 1.1 sanity\n",
    "    # ----------\n",
    "    if input_is_image == True:\n",
    "        assert torch.mean(x_in_global) > 1, 'Error: Data already in 0-1 range'\n",
    "        x_in_global = x_in_global/torch.max(x_in_global)\n",
    "        \n",
    "    \n",
    "    # 2. calling pool function\n",
    "    # ------------------------\n",
    "    pool = ThreadPool(10)\n",
    "    pool.map(simple_forward_pass_single, list(range(xin.size()[0])))\n",
    "    print('Done with forward pass of around ' + str(xin.size()[0]) + ' examples.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def simple_forward_pass_single(i):\n",
    "    \n",
    "    # 0. global inits\n",
    "    # ---------------\n",
    "    global model_global\n",
    "    global x_in_global\n",
    "    global y_out_global\n",
    "    \n",
    "    # 1. ops\n",
    "    # ------\n",
    "    curr_example = x_in_global[i]\n",
    "    curr_example = curr_example.view(1,curr_example.size()[0],curr_example.size()[1],curr_example.size()[2])\n",
    "    curr_out = model_global(curr_example)\n",
    "    y_out_global[i] = curr_out[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "# -------------\n",
    "\n",
    "def return_ms_rmac(fmaps_list,pool_mode,kernel_dims,aggregate_pool_maps):\n",
    "    \n",
    "    '''\n",
    "    ref: https://www.researchgate.net/publication/313465134_MS-RMAC_Multiscale_Regional_Maximum_Activation_of_Convolutions_for_Image_Retrieval\n",
    "    \n",
    "    1. takes as input fmaps tuple with feature masps of size (m,k,h,w) each where k = no_channels at each layer\n",
    "    -- input is ((m1,k1,h1,w1), (m2,k2,h2,w2),...)\n",
    "    -- pool_mode = 'max','avg','both'\n",
    "    -- kernel_dims = None or (f,s)\n",
    "    -- aggregate_pool_maps - if true, we will sum across channels, else leave as it is\n",
    "    \n",
    "    2. works out 3 scales of MAC kernel sizes for each feature map in tuple\n",
    "    3. computes MAC i.e., maximum activations convolutions & aggregates them\n",
    "    4. returns concatenated (m,K) vector where K = k1 + k2 + k3.. i.e., no_channels at each layer in fmaps in tuple\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # -------------------\n",
    "    assert type(fmaps_list) == list, 'Type error: input feature maps must be a list'\n",
    "    \n",
    "    \n",
    "    # 1. looping through fmap tuple\n",
    "    # -----------------------------\n",
    "    for fmap in fmaps_list:\n",
    "        \n",
    "        # 1.1 checking kernel initialisations\n",
    "        # -----------------------------------\n",
    "        if kernel_dims == None:\n",
    "            \n",
    "            # 1.1.1 we will be using preset scaled regions - computing f,s\n",
    "            # ------------------------------------------------------------\n",
    "            h,w = fmap.size()[2],fmap.size()[3]\n",
    "\n",
    "            # scale 1 : w is same, h = h/2, stride = curr_h/3\n",
    "            ##\n",
    "            l1_h = int(h/2)\n",
    "            l1_w = w\n",
    "            l1_s = int(l1_h/2)\n",
    "\n",
    "            # scale 2 : h = h/2, w = 2w/3, stride = curr_w/2\n",
    "            ##\n",
    "            l2_h = int(h/2)\n",
    "            l2_w = int(2*w/3)\n",
    "            l2_s = int(l2_w/2)\n",
    "\n",
    "            # scale 3 : h = 2h/5, w = w/2, stride = curr_w/2\n",
    "            ##\n",
    "            l3_h = int(2*h/5)\n",
    "            l3_w = int(w/2)\n",
    "            l3_s = int(l3_w/2)\n",
    "            \n",
    "            \n",
    "            # 1.1.1.2 forward pass to get pool maps\n",
    "            # --------------------------------------\n",
    "            if pool_mode == 'max':\n",
    "                \n",
    "                # computing mx pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.MaxPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.MaxPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.MaxPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # -----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map\n",
    "                \n",
    "                \n",
    "            \n",
    "            elif pool_mode == 'avg':\n",
    "                \n",
    "\n",
    "                # computing avg pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.AvgPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.AvgPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.AvgPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # ----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map\n",
    "                \n",
    "                \n",
    "            elif pool_mode == 'both':\n",
    "                \n",
    "                # computing mx pool @ scale 1\n",
    "                # ---------------------------\n",
    "                pl_l1 =  nn.Sequential(*[nn.MaxPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                l1_pool_map = pl_l1(fmap)\n",
    "                l1_pool_map = torch.sum(torch.sum(l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 2\n",
    "                # ---------------------------\n",
    "                pl_l2 =  nn.Sequential(*[nn.MaxPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                l2_pool_map = pl_l2(fmap)\n",
    "                l2_pool_map = torch.sum(torch.sum(l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing mx pool @ scale 3\n",
    "                # ---------------------------\n",
    "                pl_l3 =  nn.Sequential(*[nn.MaxPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                l3_pool_map = pl_l3(fmap)\n",
    "                l3_pool_map = torch.sum(torch.sum(l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # computing avg pool @ scale 1\n",
    "                # ---------------------------\n",
    "                avg_pl_l1 =  nn.Sequential(*[nn.AvgPool2d((l1_h,l1_w), stride=l1_s)])\n",
    "                avg_l1_pool_map = avg_pl_l1(fmap)\n",
    "                avg_l1_pool_map = torch.sum(torch.sum(avg_l1_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 2\n",
    "                # ---------------------------\n",
    "                avg_pl_l2 =  nn.Sequential(*[nn.AvgPool2d((l2_h,l2_w), stride=l2_s)])\n",
    "                avg_l2_pool_map = avg_pl_l2(fmap)\n",
    "                avg_l2_pool_map = torch.sum(torch.sum(avg_l2_pool_map, 2),2)\n",
    "                \n",
    "                # computing avg pool @ scale 3\n",
    "                # ---------------------------\n",
    "                avg_pl_l3 =  nn.Sequential(*[nn.AvgPool2d((l3_h,l3_w), stride=l3_s)])\n",
    "                avg_l3_pool_map = avg_pl_l3(fmap)\n",
    "                avg_l3_pool_map = torch.sum(torch.sum(avg_l3_pool_map, 2),2)\n",
    "                \n",
    "                \n",
    "                # NOT concatenating -- summing\n",
    "                # ----------------------------\n",
    "                combined_pool_map = l1_pool_map + l2_pool_map + l3_pool_map + avg_l1_pool_map + avg_l2_pool_map + avg_l3_pool_map\n",
    "\n",
    "            else:\n",
    "                \n",
    "                assert 1 == 2,'Error: invalid pool mode'\n",
    "                \n",
    "            \n",
    "            # 1.1.1.3 finally concatenating pool maps across all input feature maps\n",
    "            # ---------------------------------------------------------------------\n",
    "            try:\n",
    "                all_layers_pool_map = torch.cat((all_layers_pool_map,combined_pool_map), 1)\n",
    "            except:\n",
    "                all_layers_pool_map = combined_pool_map\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # if the input dims are given\n",
    "        # ---------------------------\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            # 1.1.2 dims is given as (f,s)\n",
    "            # ----------------------------\n",
    "            curr_f = kernel_dims[0]\n",
    "            curr_s = kernel_dims[1]\n",
    "            \n",
    "            # 1.1.2.1 setting up sequentials\n",
    "            # ------------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((curr_f,curr_f), stride=curr_s)])\n",
    "            avgpl =  nn.Sequential(*[nn.AvgPool2d((curr_f,curr_f), stride=curr_s)])\n",
    "            \n",
    "            \n",
    "            # 1.1.2.2 forward pass to get pool maps\n",
    "            # --------------------------------------\n",
    "            if pool_mode == 'max':\n",
    "                \n",
    "                # computing max pool\n",
    "                # ------------------\n",
    "                pool_map = mxpl(fmap)\n",
    "\n",
    "            \n",
    "            elif pool_mode == 'avg':\n",
    "                \n",
    "                # computing avg pool\n",
    "                # ------------------\n",
    "                pool_map = avgpl(fmap)\n",
    "            \n",
    "            elif pool_mode == 'both':\n",
    "                \n",
    "                # computing both\n",
    "                # --------------\n",
    "                mx_pool_map = mxpl(fmap)\n",
    "                avg_pool_map = avgpl(fmap)\n",
    "                \n",
    "                # concatenating\n",
    "                # -------------\n",
    "                #pool_map = torch.cat((mx_pool_map,avg_pool_map), 1)\n",
    "                pool_map = mx_pool_map + avg_pool_map\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                assert 1 == 2,'Error: invalid pool mode'\n",
    "            \n",
    "            # 1.1.2.3 aggregating\n",
    "            # -------------------\n",
    "            if aggregate_pool_maps == True:\n",
    "                \n",
    "                # summing along h,w axises - pool_map will be of shape (m,no_channels)\n",
    "                # --------------------------------------------------------------------\n",
    "                pool_map = torch.sum(torch.sum(pool_map, 2),2)\n",
    "                \n",
    "            \n",
    "            # final resize before concat\n",
    "            # --------------------------\n",
    "            pool_map = pool_map.view(pool_map.size()[0],-1)\n",
    "            \n",
    "            \n",
    "            # final concat along channel axis\n",
    "            # --------------------------------\n",
    "            try:\n",
    "                all_layers_pool_map = torch.cat((all_layers_pool_map,pool_map), 1)\n",
    "            except:\n",
    "                all_layers_pool_map = pool_map\n",
    "                \n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return all_layers_pool_map\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will return final latents for similarity function \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def final_latents(f_maps,kernel_stride_dims,pool_mode,aggregate_pool_maps):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. input is a dict with keys - \n",
    "    \n",
    "    a. f_maps - list of feature maps (m,c,h,w) on which pooling functions can be run for latent computation\n",
    "    b. kernel_dims - list of kernel dimensions that will be used for pooling on feature maps\n",
    "    c. pool_mode - 'max', 'avg' or 'both'\n",
    "    d. aggregate_pool_maps - either sum up pool values or not\n",
    "    \n",
    "    2. output will be a dict with final latents to be input to similarity function\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    latents_out = []\n",
    "    \n",
    "    \n",
    "    # 1. computing rmac latents\n",
    "    # -------------------------\n",
    "    for each_fmap in f_maps:\n",
    "        for each_kernel_dim in kernel_stride_dims:\n",
    "            curr_latent = return_ms_rmac([each_fmap],pool_mode,each_kernel_dim,aggregate_pool_maps).data.numpy()\n",
    "            latents_out.append(curr_latent)\n",
    "            print('done at kernel ' + str(each_kernel_dim) + '. latent size: ' + str(curr_latent.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return latents_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to simply return similar images based on whole latents\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def similarity(input_latents_list,db_latents_list,xin,xdb,sim_weights,no_suggestions,similarity_check_mode,print_result):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. input includes\n",
    "    \n",
    "    a. input images & db images latent lists\n",
    "    b. settings such as weights, mode etc\n",
    "    c. will return indices of db images sorted in descending order of ranking similarity\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. initialisations\n",
    "    # ------------------\n",
    "    interim_sim_array = {}\n",
    "    final_sim_array = {}\n",
    "    final_all_indices = []\n",
    "    similar_products = []\n",
    "    all_similarity_values = []\n",
    "    epsilon = 0.0001\n",
    "    \n",
    "    # 2. sanity assertions\n",
    "    # --------------------\n",
    "    assert len(input_latents_list) == len(db_latents_list), 'Error: length of input & db lists dont match.'\n",
    "    if sim_weights == 'equal':\n",
    "        \n",
    "        # setting sim weight values to 1\n",
    "        # ------------------------------\n",
    "        sim_weights = []\n",
    "        for _ in range(len(input_latents_list)):\n",
    "            sim_weights.append(1.0)\n",
    "    else:\n",
    "        assert len(sim_weights) == len(input_latents_list), 'Error: number of weights & length of latent lists dont match.'\n",
    "        #assert round(sum(sim_weights),2) == 1.0, 'Error: the weights dont sum to 1.0'\n",
    "    \n",
    "    # 3. looping through the INPUT latents list\n",
    "    # -----------------------------------------\n",
    "    print('1. looping through latent list..')\n",
    "    for l_counter in range(len(input_latents_list)):\n",
    "        \n",
    "        # 3.0 local initialisations\n",
    "        # -------------------------\n",
    "        curr_input_latent = input_latents_list[l_counter]\n",
    "        db_input_latent = db_latents_list[l_counter]\n",
    "        \n",
    "        \n",
    "        # 3.1 itering through every image in curr_input_latent\n",
    "        # ----------------------------------------------------\n",
    "        for i in range(curr_input_latent.shape[0]):\n",
    "            \n",
    "            # Finding similarity per example\n",
    "            # ------------------------------\n",
    "            curr_input_latent_example = curr_input_latent[i]\n",
    "            \n",
    "            \n",
    "            # checking using similarity\n",
    "            # -------------------------\n",
    "            if similarity_check_mode == 'cosine_ratio':\n",
    "                \n",
    "                # using cosine_ratio\n",
    "                # ------------------\n",
    "                curr_input_latent_example = curr_input_latent_example.reshape(1,curr_input_latent_example.shape[0])\n",
    "                similarity_array = cosine_similarity_multi(curr_input_latent_example,db_input_latent)\n",
    "                similarity_array = similarity_array.reshape(similarity_array.shape[0],)\n",
    "                similarity_array += np.average((np.minimum(curr_input_latent_example,db_input_latent)/(np.maximum(curr_input_latent_example,db_input_latent) + epsilon)), axis = 1)\n",
    "            \n",
    "            elif similarity_check_mode == 'ratio':\n",
    "                \n",
    "                # ratio only\n",
    "                # ----------\n",
    "                similarity_array = np.average((np.minimum(curr_input_latent_example,db_input_latent)/(np.maximum(curr_input_latent_example,db_input_latent) + epsilon)), axis = 1)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # invalid sim check mode\n",
    "                # ----------------------\n",
    "                assert 1 == 2, 'Error: invalid similarity check mode. This can be either \"cosine_ratio\" or \"ratio\" only.'\n",
    "            \n",
    "            \n",
    "            # appending to interim sim array for final weights application\n",
    "            # ------------------------------------------------------------\n",
    "            \n",
    "            # this dict will store all similarity values per example\n",
    "            # that is - \n",
    "            # interim_sim_array[0] = [sim_array_based_on_latent_list_0, sim_array_based_on_latent_list_1,...]\n",
    "            \n",
    "            try:\n",
    "                interim_sim_array[i].append(similarity_array)\n",
    "            except:\n",
    "                interim_sim_array[i] = []\n",
    "                interim_sim_array[i].append(similarity_array)\n",
    "    \n",
    "    \n",
    "    # 4. itering thru dict & applying weights\n",
    "    # ---------------------------------------\n",
    "    print('2. applying weights & appending final results..')\n",
    "    for keys in interim_sim_array:\n",
    "        \n",
    "        # deleting old value\n",
    "        # ------------------\n",
    "        try:\n",
    "            del similarity_array_final\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # itering thru list\n",
    "        # -----------------\n",
    "        for each_sim_array_index in range(len(interim_sim_array[keys])):\n",
    "            curr_weighted_array = interim_sim_array[keys][each_sim_array_index] * sim_weights[each_sim_array_index]\n",
    "            try:\n",
    "                similarity_array_final += curr_weighted_array\n",
    "            except:\n",
    "                similarity_array_final = curr_weighted_array\n",
    "                \n",
    "                \n",
    "        # similarity_array_final must be of shape (m,)\n",
    "        ###\n",
    "        \n",
    "        # continuation - no change here on\n",
    "        # --------------------------------\n",
    "        sorted_indices = list(np.argsort(-1*similarity_array_final))\n",
    "        final_indices = sorted_indices[0:no_suggestions]\n",
    "        final_indices = [int(fi) for fi in final_indices]\n",
    "        final_all_indices.append(final_indices)\n",
    "        all_similarity_values.append(similarity_array[final_indices])\n",
    "        similar_products.append(xdb[final_indices])\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    # 3. showing if required\n",
    "    # ----------------------\n",
    "    if print_result == True:\n",
    "        \n",
    "        # itering\n",
    "        # -------\n",
    "        for i in range(xin.shape[0]):\n",
    "            \n",
    "            print('>> At image ' + str(i) + ' of around ' + str(xin.shape[0]) + '..')\n",
    "            print('** Input Image - ')\n",
    "            plt.figure(figsize=(2,2))\n",
    "            plt.imshow(xin[i])\n",
    "            plt.show()\n",
    "           \n",
    "            print('** Showing result images..')\n",
    "            fig=plt.figure(figsize=(25, 25))\n",
    "            columns = 5\n",
    "            rows = 10\n",
    "            \n",
    "            \n",
    "            for i_1 in range(similar_products[i].shape[0]):\n",
    "                \n",
    "                #print('** At image ' + str(i) + ' showing option number ' + str(i_1) + '**')\n",
    "                #print('Image index number: ' + str(final_all_indices[i][i_1]))\n",
    "                #print('Similarity value: ' + str(all_similarity_values[i][i_1]))\n",
    "                \n",
    "                if xdb.shape[3] > 1:\n",
    "                    img = similar_products[i][i_1]\n",
    "                    fig.add_subplot(rows, columns, i_1+1)\n",
    "                    plt.imshow(img)\n",
    "                    #plt.show()\n",
    "                else:\n",
    "                    img = similar_products[i][i_1,:,:,0]\n",
    "                    fig.add_subplot(rows, columns, i_1+1)\n",
    "                    plt.imshow(img, cmap='gray')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            print('\\n#########################################\\n')\n",
    "                \n",
    "            \n",
    "    \n",
    "    # 3. final return\n",
    "    # ---------------\n",
    "    return similar_products,all_similarity_values,final_all_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_3_layer_std(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        #up_conv1 = 128\n",
    "        #t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        #b1 = nn.BatchNorm2d(up_conv1)\n",
    "        #a1 = nw_activation_conv\n",
    "        #l1 = [t1,b1,a1,dropout_node]\n",
    "        #self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(conv3,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,in_channels,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        #f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(c3_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        latent_out = self.convl3(c2_out)\n",
    "            \n",
    "        \n",
    "        return latent_out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps to create a UNET AE to get embeddings\n",
    "# -------------------------------------------\n",
    "\n",
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class conv_classifier_gap(nn.Module):\n",
    "    def __init__(self, in_channels, out_nodes, target_act):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is UNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (175,175) -- Insize\n",
    "        \n",
    "        # @conv1 - (87, 87) @ f=3,s=2\n",
    "        # @conv2 - (43, 43) @ f=3,s=2\n",
    "        # @conv3 - (21, 21) @ f=3,s=2\n",
    "        # @conv4 - (10, 10) @ f=3,s=2\n",
    "        # Followed by a an avg pool (10,10) to make this 1,1\n",
    "        \n",
    "\n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        self.target_act = target_act\n",
    "        dropout_prob = 0.10\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 256\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        #conv5 = 256\n",
    "        #ct5 = nn.Conv2d(conv4,conv5,4,stride = s)\n",
    "        #cb5 = nn.BatchNorm2d(conv5)\n",
    "        #ca5 = nw_activation_conv\n",
    "        #cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        #self.convl5 = nn.Sequential(*cl5)\n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        avpl =  [nn.AvgPool2d((10,10), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "        # setting latent size\n",
    "        # -------------------\n",
    "        latent_size = conv4 * 1 * 1\n",
    "        \n",
    "        # Adding linear layers\n",
    "        # -------------------\n",
    "        #lnt1 = nn.Linear(latent_size,bottle_neck_nodes)\n",
    "        #lnb1 = nn.BatchNorm1d(bottle_neck_nodes)\n",
    "        #lna1 = nw_activation_conv\n",
    "        #ln1 = [lnt1,lnb1,lna1,dropout_node]\n",
    "        #self.linear1 = nn.Sequential(*ln1)\n",
    "      \n",
    "        #lnt2 = nn.Linear(128,64)\n",
    "        #lnb2 = nn.BatchNorm1d(64)\n",
    "        #lna2 = nw_activation_conv\n",
    "        #ln2 = [lnt2,lnb2,lna2,dropout_node]\n",
    "        #self.linear2 = nn.Sequential(*ln2)\n",
    "        \n",
    "        # last output node\n",
    "        # ----------------\n",
    "        if target_act == 'sigmoid':\n",
    "            target_activation = nn.Sigmoid()\n",
    "        else:\n",
    "            target_activation = nn.Softmax()\n",
    "        ln4 = [nn.Linear(latent_size,out_nodes), target_activation]\n",
    "        self.linear4 = nn.Sequential(*ln4)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c4_out).view(c4_out.size()[0],-1)\n",
    "        \n",
    "        # linear out\n",
    "        # ---------\n",
    "        lin_out = self.linear4(latent_out)\n",
    "      \n",
    "        return lin_out\n",
    "    \n",
    "    \n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c4_out).view(c4_out.size()[0],-1)\n",
    "        \n",
    "        \n",
    "        return latent_out\n",
    "    \n",
    "    \n",
    "    def model_cam(self, x, print_maps):\n",
    "        \n",
    "        # doing a forward pass & getting self variables\n",
    "        # ---------------------------------------------\n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        \n",
    "        # setting up f_maps here for CAM\n",
    "        # ------------------------------\n",
    "        self.f_maps = c4_out\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c4_out).view(c4_out.size()[0],-1)\n",
    "        \n",
    "        # setting up predictions & weights for CAM\n",
    "        # ----------------------------------------\n",
    "        self.predictions = self.linear4(latent_out)\n",
    "        self.w = self.linear4[0].weight\n",
    "        \n",
    "        \n",
    "        # all variables required for cam ops is here\n",
    "        # ------------------------------------------\n",
    "        # self.f_maps\n",
    "        # self.predictions\n",
    "        # self.w\n",
    "        # self.target_act\n",
    "        # self.print_maps\n",
    "        \n",
    "        # setting up input\n",
    "        # ----------------\n",
    "        xin = to_numpy_image(x) * 255\n",
    "        \n",
    "        # setting up predictions\n",
    "        # ----------------------\n",
    "        yin = to_one_hot(self.predictions,self.target_act)\n",
    "        \n",
    "        # calling cam function\n",
    "        # --------------------\n",
    "        map_d,classes_d = cam(xin, self.f_maps, yin, self.w, print_maps)\n",
    "        \n",
    "        # final return\n",
    "        # ------------\n",
    "        return map_d,classes_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_4_layer_std(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv #nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 512\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nn.Softmax2d()#nw_activation_conv #nn.Softmax2d() #nw_activation_conv\n",
    "        cl4 = [ct4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,in_channels,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "            \n",
    "        \n",
    "        return c4_out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_5_layer_std(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv #nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 512\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv#nw_activation_conv #nn.Softmax2d() #nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv5 = 1024\n",
    "        ct5 = nn.Conv2d(conv4,conv5,2,stride = 2)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nn.Softmax2d()#nw_activation_conv #nn.Softmax2d() #nw_activation_conv\n",
    "        cl5 = [ct5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = 512\n",
    "        t0 = nn.ConvTranspose2d(conv5,up_conv0,2,stride = 2)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0]\n",
    "        self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(up_conv0,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,in_channels,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        \n",
    "        f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(f1_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "            \n",
    "        return c5_out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. set ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "# ----------------\n",
    "\n",
    "# gpu setup\n",
    "# ----------\n",
    "use_cuda = False\n",
    "\n",
    "# image urls\n",
    "# ---------\n",
    "input_query_url = '/Users/venkateshmadhava/Documents/si_projects/datasets/si_input_queries'\n",
    "search_db_url = '/Users/venkateshmadhava/Documents/si_projects/datasets/si_dataset_1'\n",
    "\n",
    "# model urls\n",
    "# ----------\n",
    "model_ae_url = '/Users/venkateshmadhava/Documents/pmate2/pmate2_env/models/ae_model_tboard_4_layer_512_softmax_RGB.tar'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. extract feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input features - using extract function\n",
    "# extract_feature_maps(images_url, using_bw_only, model_url, use_cuda)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fmaps_input_rgb,x_input = extract_feature_maps(input_query_url,False,model_ae_url,use_cuda)\n",
    "fmaps_input_gy,_ = extract_feature_maps(input_query_url,True,model_ae_url,use_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DB features - using extract function\n",
    "# extract_feature_maps(images_url, using_bw_only, model_url, use_cuda)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fmaps_db_rgb,x_db = extract_feature_maps(search_db_url,False,model_ae_url,use_cuda)\n",
    "fmaps_db_gy,_ = extract_feature_maps(search_db_url,True,model_ae_url,use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. maximum activation pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# LATENT SETTINGS #################\n",
    "###################################################\n",
    "\n",
    "# latents settings\n",
    "# ----------------\n",
    "kernel_stride_dims = [(2,2),[10,10]]\n",
    "pool_mode = 'both'\n",
    "aggregate_pool_maps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing db latents from fmaps\n",
    "# -------------------------------\n",
    "\n",
    "db_latents_list = final_latents([fmaps_db_rgb,fmaps_db_gy],kernel_stride_dims,pool_mode,aggregate_pool_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing input latents from fmaps\n",
    "# -------------------------------\n",
    "\n",
    "input_latents_list = final_latents([fmaps_input_rgb,fmaps_input_gy],kernel_stride_dims,pool_mode,aggregate_pool_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any other latents here\n",
    "# -------------------------\n",
    "\n",
    "'''\n",
    "\n",
    "# 1. if another latents, say vienna codes pred is available as a (m,dim) array, append that to the list\n",
    "# 2. the final input to the similarity function must be input_latents_list & db_latents_list\n",
    "\n",
    "'''\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF MAXIMUM ACTIVATION POOLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. final similarity ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity setting\n",
    "# ------------------\n",
    "\n",
    "# latent list format -- [rgb_local, rgb_global, gy_local, gy_global]\n",
    "#sim_weights = [1,3,0,0], 'ratio' -- was generalising ok with more results displayed, most relevant ones should surface.. \n",
    "\n",
    "\n",
    "sim_weights = [1,3,0,0] #'equal'\n",
    "similarity_check_mode = 'ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# similarity(input_latents_list,db_latents_list,xin,xdb,sim_weights,no_suggestions,similarity_check_mode,print_result):\n",
    "\n",
    "\n",
    "_,_,_ = similarity(input_latents_list,db_latents_list,x_input,x_db,sim_weights,50,similarity_check_mode,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmate2_env",
   "language": "python",
   "name": "pmate2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
